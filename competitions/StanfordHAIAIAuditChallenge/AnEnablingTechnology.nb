(* Content-type: application/vnd.wolfram.mathematica *)

(*** Wolfram Notebook File ***)
(* http://www.wolfram.com/nb *)

(* CreatedBy='Mathematica 13.0' *)

(*CacheID: 234*)
(* Internal cache information:
NotebookFileLineBreakTest
NotebookFileLineBreakTest
NotebookDataPosition[       158,          7]
NotebookDataLength[     15062,        346]
NotebookOptionsPosition[     12523,        296]
NotebookOutlinePosition[     13003,        315]
CellTagsIndexPosition[     12960,        312]
WindowFrame->Normal*)

(* Beginning of Notebook Content *)
Notebook[{

Cell[CellGroupData[{
Cell["An Enabling Technology", "Title",
 CellChangeTimes->{{3.870419228724147*^9, 
  3.870419236741494*^9}},ExpressionUUID->"2bf084ac-b82f-4f6f-bfdc-\
97f24710e1d2"],

Cell["\<\
Evaluators like the independent trio evaluator can enable many applications \
that can increase the safety and fairness of AI systems. This notebooks \
explores some of them and gives suggestions for possible experiments to carry \
out.\
\>", "Text",
 CellChangeTimes->{{3.8704192488339033`*^9, 
  3.870419348980008*^9}},ExpressionUUID->"c5793477-1d2f-43c0-8054-\
dcadbc170a7f"],

Cell[CellGroupData[{

Cell["Auto-ML", "Section",
 CellChangeTimes->{{3.870419415065234*^9, 
  3.870419419130657*^9}},ExpressionUUID->"d80b9efa-8cbf-468b-83e5-\
f7ce8ab93566"],

Cell["\<\
The vast majority of data that an AI system will process is unlabeled. \
Otherwise, why was the AI used? Can we leverage that unlabeled data somehow? \
Could we devise protocols that can train good models using unlabeled data? \
And can we do this robustly? The experiments in this section explore these \
questions.\
\>", "Text",
 CellChangeTimes->{{3.8704194263428173`*^9, 
  3.870419603508255*^9}},ExpressionUUID->"dd256733-f784-4d73-8ec8-\
cb25b4e1c690"],

Cell[CellGroupData[{

Cell["\<\
Finding least correlated ensembles on large unlabeled test sets\
\>", "Subsubsection",
 CellChangeTimes->{{3.870710552046773*^9, 
  3.8707105790798798`*^9}},ExpressionUUID->"cbd2ea44-d894-4551-a7f5-\
81c14d2916af"],

Cell["\<\
The problem of correlated classifiers is the Achilles heel of algebraic \
evaluators. This presents the engineer of robust AI systems  that uses them \
with a challenge - how do we build ensembles of classifiers that are, as best \
we can, independently correlated in their errors on a large unlabeled test \
set? We use the failures of the independent trio formula to reject possible \
candidates. Here are some suggestions on what sort of scans you could do to \
see how well this works on the data and the classifiers of interest to you.\
\>", "Text",
 CellChangeTimes->{{3.87071059173975*^9, 3.870710909108316*^9}, {
  3.8707124290707827`*^9, 
  3.870712429915091*^9}},ExpressionUUID->"47b41ef7-f703-4487-9f97-\
97e42aed241f"],

Cell[CellGroupData[{

Cell["\<\
We expect classifiers trained differently to perform differently. Thus \
differences in training decorrelate their errors also. By training on \
disjoint sets of data, features, or algorithms you can get pair error \
correlations in the order of 5% or less. Carry out training protocols that \
scan for the most independent classifier ensembles by discarding the ones \
that make the evaluator fail.\
\>", "ItemNumbered",
 CellChangeTimes->{{3.8707109501452303`*^9, 
  3.870711177436925*^9}},ExpressionUUID->"d93054fa-6da0-4605-a9db-\
85a7493b5803"],

Cell["\<\
Are there bounds on the correlations observed in the selected ones?\
\>", "SubitemNumbered",
 CellChangeTimes->{{3.8707109501452303`*^9, 
  3.870711205906043*^9}},ExpressionUUID->"adaac6b5-b7b3-49ca-977f-\
ffa04b1eacc0"],

Cell["\<\
What about the rejected ones? Were good configurations rejected? What was the \
least error correlation that triggered the rejection? Is there a difference \
between failures that resulted in real algebraic numbers versus those that \
gave imaginary algebraic numbers?\
\>", "SubitemNumbered",
 CellChangeTimes->{{3.8707109501452303`*^9, 
  3.870711348794435*^9}},ExpressionUUID->"2baadf67-07c0-4c6d-9302-\
1ee4d2341659"],

Cell["\<\
Now measure the error in the evaluation estimates of the accepted \
configurations. Compare that to the error in the rejected ones. \
\>", "SubitemNumbered",
 CellChangeTimes->{{3.8707109501452303`*^9, 
  3.87071149348573*^9}},ExpressionUUID->"5d628b60-9b55-4b0f-9a23-\
41a7ff40e974"],

Cell["\<\
Also compare it to various other random guessing that would be sensible - a \
real number between 0 and 1. These random guessers are good proxies for \
having no information except the one that you need to make in order to decode \
the multiple answers given by algebraic evaluators. For example, the \
comparison we made between the evaluator and ground truth in \
TheCoreTheorem.nb was based on picking the one based on our side knowledge \
about the value of the true prevalence. For binary classification this means \
that a fair comparison with random performers would mean that you guess a \
value of the prevalence with a width specified by your side knowledge. In our \
case, random guessing on the 0 to 1/2 interval.\
\>", "SubitemNumbered",
 CellChangeTimes->{{3.8707109501452303`*^9, 3.870711504682041*^9}, {
  3.870711538259502*^9, 
  3.870711811724036*^9}},ExpressionUUID->"4025b159-b23c-436b-9750-\
86b73e27da7c"]
}, Open  ]]
}, Open  ]]
}, Open  ]],

Cell[CellGroupData[{

Cell["Fairness Alarms", "Section",
 CellChangeTimes->{{3.870419626623508*^9, 
  3.870419637682036*^9}},ExpressionUUID->"899e9430-2ad3-4ee7-a733-\
764d8aac9ddf"],

Cell["\<\
Different methods for ameliorating the harm of biased AI systems have been \
proposed and criticized. Common to some of them, is the use of purely \
observational statistics like false positives, etc. But how do we know that a \
system that was designed for X measure of fairness is actually working on \
unlabeled data? The experiment in this section suggests one possible way to \
use the independent trio evaluator to help with this problem.\
\>", "Text",
 CellChangeTimes->{{3.8704196530998917`*^9, 3.870419849691124*^9}, {
  3.87071182745879*^9, 
  3.870711829553699*^9}},ExpressionUUID->"4b07fa6c-ef39-43cc-aa70-\
74de8578e81b"],

Cell["\<\
Various approaches to creating and measuring the fairness of AI algorithms \
have been proposed in the scientific literature. There is even some \
disagreement about whether some approaches are better than others. The \
experiments proposed here are based on a bias mitigation training strategy \
by, \
\>", "ItemNumbered",
 CellChangeTimes->{{3.870749468501769*^9, 3.8707496133822727`*^9}, {
  3.870749678246545*^9, 3.870749679486217*^9}, {3.870749873392499*^9, 
  3.870749873398354*^9}},ExpressionUUID->"d75ef218-daeb-4cb2-825b-\
75dbfdbc845f"],

Cell[CellGroupData[{

Cell["\<\
\[OpenCurlyDoubleQuote]Contrastive Counterfactual Fairness in Algorithmic \
Decision-Making\[CloseCurlyDoubleQuote] by Mutlu, Yousefi, and Garibay \
discusses a way to use counterfactual reasoning ideas from Causal Data \
Science. They propose an algorithm for augmenting training data to mitigate \
the bias of AI algorithms. Their approach can be combined with the algebraic \
evaluators to create a monitor for fairness on unlabeled data.\
\>", "ItemNumbered",
 CellChangeTimes->{
  3.870750114423814*^9, {3.8707503717479467`*^9, 3.870750605295458*^9}, {
   3.870750960882509*^9, 
   3.870751040657379*^9}},ExpressionUUID->"4f8c9ee4-94e7-49e1-83b7-\
915c42bf28a1"],

Cell["\<\
The UCI Adult dataset was used in their paper. Using the same dataset, \
implement their data augmentation technique to create fairer AI algorithms. \
Using the same ideas about AutoML mentioned before, suppose that you \
constructed a monitoring ensemble that was roughly independent on its test \
errors. Can you use the accuracy estimates given by the algebraic evaluator \
for the members of that ensemble to, in turn, estimate their fairness on \
unlabeled data? What is the estimation error of your fairness thermometer on \
unlabeled data?\
\>", "SubitemNumbered",
 CellChangeTimes->{
  3.870750114423814*^9, {3.8707503717479467`*^9, 
   3.870750918971902*^9}},ExpressionUUID->"4bcda486-b026-490c-83da-\
5ade0999be37"]
}, Open  ]]
}, Open  ]],

Cell[CellGroupData[{

Cell["Error-Correction Codes", "Section",
 CellChangeTimes->{{3.87041986255299*^9, 
  3.870419868387034*^9}},ExpressionUUID->"19d559e9-4d8e-4f59-bf6d-\
9789a4ff8ebc"],

Cell[TextData[{
 "Hamming famously quipped - \[OpenCurlyDoubleQuote]Damn it, if the computer \
knows I am wrong, why can\[CloseCurlyQuote]t it fix it?\
\[CloseCurlyDoubleQuote] He went on to invent error correcting codes. What \
error-correcting codes can you invent with the independent trio evaluator? \
Here we propose one way to build a code to help you get going with your own \
ideas.\n\nThe connection between algebraic evaluators and error-correcting \
for AI algorithms is as follows. Constructing evaluation ideals for noisy \
judges relies on the implicit assumption that classification labels allow us \
to disjointly separate the test set. This means that the following equation \
is always true by definition,\n",
 Cell[BoxData[
  FormBox[
   RowBox[{
    SubscriptBox["f", 
     RowBox[{"voting", " ", "pattern"}]], "=", " ", 
    RowBox[{
     SubscriptBox["f", 
      RowBox[{
      "voting", " ", "pattern", " ", "when", " ", "label", " ", "a", " ", 
       "was", " ", "correct"}]], "+"}]}], TraditionalForm]],
  FormatType->TraditionalForm,ExpressionUUID->
  "c74a27bc-4701-4f9a-a291-f5ca2881ab5b"],
 " ",
 Cell[BoxData[
  FormBox[
   RowBox[{
    SubscriptBox["f", 
     RowBox[{
     "voting", " ", "pattern", " ", "when", " ", "label", " ", "b", " ", 
      "was", " ", "correct"}]], "+", 
    SubscriptBox["f", 
     RowBox[{
      RowBox[{
       RowBox[{"voting", " ", "pattern", " ", "when", " ", "label"}], " ", 
       "..."}], "."}]]}], TraditionalForm]],
  FormatType->TraditionalForm,ExpressionUUID->
  "a36ae783-a0dc-4f73-aa9c-4657475ba64d"],
 "\nFor binary classification that means the number of instances of a \
particular voting pattern is a sum of two unknown integers. Each unknown \
integer tells you the correct number of instances for that label. \
Error-correcting with this observation follows immediately. For each voting \
pattern, compute your estimate of the number of instances for each label. \
Error minimization proceeds by labeling all the instances of the label that \
gave the smallest count as the other label.\nA quick example illustrates \
this,\n10 instances of (a,b,a) = (3 when \[OpenCurlyDoubleQuote]a\
\[CloseCurlyDoubleQuote] was correct) + (7 when \[OpenCurlyDoubleQuote]b\
\[CloseCurlyDoubleQuote] was correct)\nWe minimize the error in these \
decisions by then proceeding to label all these instances as actually being \
\[OpenCurlyDoubleQuote]b\[CloseCurlyDoubleQuote] instances. Note that we \
picked an example that would give the opposite answer than  ensemble decision \
algorithm commonly known as \[OpenCurlyDoubleQuote]wisdom of the crowd.\
\[CloseCurlyDoubleQuote]"
}], "Text",
 CellChangeTimes->{{3.870419875566077*^9, 3.870419961810975*^9}, {
  3.8704199955221024`*^9, 3.8704200253428097`*^9}, {3.87075110420511*^9, 
  3.870751237648486*^9}, {3.8707512945715837`*^9, 3.870751601842366*^9}, {
  3.870751632107531*^9, 
  3.8707520016108217`*^9}},ExpressionUUID->"35597c8c-a4ae-494e-9998-\
936a79554608"],

Cell["\<\
How effective is this error correcting method? Try it out using your \
monitoring ensemble schemes. How often does it reduce or increase errors when \
you plot it against some statistic of the ensemble\[CloseCurlyQuote]s error \
correlations?\
\>", "ItemNumbered",
 CellChangeTimes->{{3.8707520434498243`*^9, 
  3.870752181419702*^9}},ExpressionUUID->"df503f03-935b-4712-817a-\
7774ebc1818c"],

Cell["\<\
Another approach to error correction is to create as large of a monitoring \
ensemble as possible and then check for good members to include in the \
decisioning ensemble. We know from Condorcet\[CloseCurlyQuote]s famous Jury \
Theorem that better than average independent judges have high odds of \
returning correct decisions. Using four classifiers allows you to test 6 \
possible trios for failures of the independent evaluator. Can your deciding \
ensembles decrease their error by eliminating the estimates from failing \
trios and just using the decisions from apparently independent ones?\
\>", "ItemNumbered",
 CellChangeTimes->{{3.8707520434498243`*^9, 
  3.8707524483448887`*^9}},ExpressionUUID->"df7fb9e0-f9c7-425f-8f8a-\
51a557a881b8"]
}, Open  ]]
}, Open  ]]
},
WindowSize->{1413, 941},
WindowMargins->{{12, Automatic}, {1, Automatic}},
PrintingCopies->1,
PrintingPageRange->{1, Automatic},
Magnification:>1.5 Inherited,
FrontEndVersion->"13.0 for Mac OS X ARM (64-bit) (February 4, 2022)",
StyleDefinitions->"Default.nb",
ExpressionUUID->"b1746174-a414-4214-ab36-62fcc1477d99"
]
(* End of Notebook Content *)

(* Internal cache information *)
(*CellTagsOutline
CellTagsIndex->{}
*)
(*CellTagsIndex
CellTagsIndex->{}
*)
(*NotebookFileOutline
Notebook[{
Cell[CellGroupData[{
Cell[580, 22, 165, 3, 146, "Title",ExpressionUUID->"2bf084ac-b82f-4f6f-bfdc-97f24710e1d2"],
Cell[748, 27, 388, 8, 88, "Text",ExpressionUUID->"c5793477-1d2f-43c0-8054-dcadbc170a7f"],
Cell[CellGroupData[{
Cell[1161, 39, 152, 3, 101, "Section",ExpressionUUID->"d80b9efa-8cbf-468b-83e5-f7ce8ab93566"],
Cell[1316, 44, 468, 9, 122, "Text",ExpressionUUID->"dd256733-f784-4d73-8ec8-cb25b4e1c690"],
Cell[CellGroupData[{
Cell[1809, 57, 224, 5, 67, "Subsubsection",ExpressionUUID->"cbd2ea44-d894-4551-a7f5-81c14d2916af"],
Cell[2036, 64, 740, 12, 157, "Text",ExpressionUUID->"47b41ef7-f703-4487-9f97-97e42aed241f"],
Cell[CellGroupData[{
Cell[2801, 80, 559, 10, 111, "ItemNumbered",ExpressionUUID->"d93054fa-6da0-4605-a9db-85a7493b5803"],
Cell[3363, 92, 230, 5, 39, "SubitemNumbered",ExpressionUUID->"adaac6b5-b7b3-49ca-977f-ffa04b1eacc0"],
Cell[3596, 99, 431, 8, 68, "SubitemNumbered",ExpressionUUID->"2baadf67-07c0-4c6d-9302-1ee4d2341659"],
Cell[4030, 109, 294, 6, 39, "SubitemNumbered",ExpressionUUID->"5d628b60-9b55-4b0f-9a23-41a7ff40e974"],
Cell[4327, 117, 937, 15, 182, "SubitemNumbered",ExpressionUUID->"4025b159-b23c-436b-9750-86b73e27da7c"]
}, Open  ]]
}, Open  ]]
}, Open  ]],
Cell[CellGroupData[{
Cell[5325, 139, 160, 3, 101, "Section",ExpressionUUID->"899e9430-2ad3-4ee7-a733-764d8aac9ddf"],
Cell[5488, 144, 644, 11, 157, "Text",ExpressionUUID->"4b07fa6c-ef39-43cc-aa70-74de8578e81b"],
Cell[6135, 157, 556, 10, 111, "ItemNumbered",ExpressionUUID->"d75ef218-daeb-4cb2-825b-75dbfdbc845f"],
Cell[CellGroupData[{
Cell[6716, 171, 677, 12, 143, "ItemNumbered",ExpressionUUID->"4f8c9ee4-94e7-49e1-83b7-915c42bf28a1"],
Cell[7396, 185, 735, 13, 153, "SubitemNumbered",ExpressionUUID->"4bcda486-b026-490c-83da-5ade0999be37"]
}, Open  ]]
}, Open  ]],
Cell[CellGroupData[{
Cell[8180, 204, 166, 3, 101, "Section",ExpressionUUID->"19d559e9-4d8e-4f59-bf6d-9789a4ff8ebc"],
Cell[8349, 209, 2980, 59, 608, "Text",ExpressionUUID->"35597c8c-a4ae-494e-9998-936a79554608"],
Cell[11332, 270, 402, 8, 80, "ItemNumbered",ExpressionUUID->"df503f03-935b-4712-817a-7774ebc1818c"],
Cell[11737, 280, 758, 12, 174, "ItemNumbered",ExpressionUUID->"df7fb9e0-f9c7-425f-8f8a-51a557a881b8"]
}, Open  ]]
}, Open  ]]
}
]
*)

